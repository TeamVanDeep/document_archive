# 入组套餐
## 搭环境
我推荐用Anaconda配置环境，简单省心，还自带常用的库，记得把默认源改成国内清华大学镜像站的源  
Anaconda装完后，conda install tensorflow-gpu就行了，先装tensorflow-gpu再装keras，血的教训  
conda升级要慎重一点，因为装软件包会处理依赖，但是升级时它不会检查，容易破坏包依赖关系  

如果想在Linux上搞深度学习，我推荐用Manjaro发行版，Manjaro作为Linux的一个发行版，装驱动容易直观，bug少，Ubuntu操作没经验容易出现循环登入的问题  
Linux系统到后面用的挺多的，好多项目只能在Linux上跑（比如flownet2），一开始可以先放一放Linux（如果你用过Linux当我没说）  
如果已经配好环境就算了，如果连Linux都没装，就装Manjaro好了。以后如果参加比赛，可能主办方会要求代码在云服务器上跑，所以我会建议你熟悉Linux
使用U盘装Linux的时候，推荐使用rufus烧录镜像  

## 选框架
组里大部分人用的是TensorFlow，TensorFlow的中文教程和文档(http://www.tensorfly.cn/)  
Caffe难，caffe难在自定义层需要写C++，可能还需要自己编译caffe，所以一开始不推荐用caffe，一开始应该专注于模型而不是具体操作。  
Keras是对TensorFlow的再一次封装，很容易用，所以我推荐一开始用Keras入门，Keras中文文档(http://keras-cn.readthedocs.io/en/latest/)  
scikit-learn一般用于传统的机器学习方法

## 入门课程&项目
网易云课堂的吴恩达的深度学习课程，网易云课堂的内容中关于搭建模型的部分需要不少经验才能理解，视频很长，一次看不完正常，按现在的技术水平，多积累一些经验成长更快，理论可以稍微偏后一点，能复现论文的模型就算很强了  
https://mooc.study.163.com/smartSpec/detail/1001319001.htm  
Kaggle三个项目是用来加深理解  
https://www.kaggle.com/c/digit-recognizer  
https://www.kaggle.com/c/house-prices-advanced-regression-techniques  
https://www.kaggle.com/c/titanic  
然后从网上看一看觉得有趣的模型自己跑一跑看看，接下来就是借鉴他人的模型，抄几个层可以，整个套是不行的  
除了Kaggle之外，国内相似的网站有天池，阿里云的。天池的入门比赛数据集比较大，Kaggle入门比赛的数据集比较小，所以我一开始发的是Kaggle。Kaggle大部分功能是能用的，小部分用到Google服务的要翻墙，下载数据集时偶尔会出问题

## 基本水平要求
会用Git&Linux，Python会调包，了解常见&有名的模型

## 关于一般做项目的流程
数据预处理->选择合适模型->实现模型->处理预测结果  
我一般是先用IPython或者Jupyter Notebook处理数据和用小批量的数据试跑模型  
把过程整理一下做成Python脚本之后才会上所有数据    

## 做深度学习时会用到的工具
* Hyperopt 自动调参
* Netron 将保存的模型可视化

## 看论文的网站
* [PaperWeekly](https://www.paperweekly.site) 推荐论文的地方，注册需要过审核
* [arXiv](https://arxiv.org/) 水平层次不齐
* [SciHub](http://sci-hub.tw/) 某些论文在期刊上，下载要钱，这时候可以到这个网站上找找
* [NIPS Proceedings](https://papers.nips.cc/) NIPS会议上发表的论文集合
* [Google学术镜像](http://ac.scmor.com/)
